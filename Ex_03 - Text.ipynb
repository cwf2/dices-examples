{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving texts and counting words\n",
    "\n",
    "In this example, we'll retrieve the texts of speeches from a remote server and do a basic word count.\n",
    "\n",
    "## Scenario\n",
    "\n",
    "Let's say we want to know how many words Achilles speaks to each of his interlocutors. We can search the DICES database for the relevant speeches using the API. Then, to count the number of words, we'll have to retrieve the text of the speeches themselves. Since the DICES *Speech* objects include CTS URNS, we can request the passages from a remote server. \n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "### The DICES API\n",
    "\n",
    "First step is to instantiate a connection to the DICES api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicesapi import DicesAPI\n",
    "from dicesapi.jupyter import NotebookPBar\n",
    "api = DicesAPI(\n",
    "    progress_class=NotebookPBar,\n",
    "    logfile='dices.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to the digital library\n",
    "\n",
    "Text-retrieval and processing tools are moving to the module `text`. We retrieve the text from an online (or locally mirrored) digital library. By default, it's Perseus's [CTS endpoint](https://scaife-cts.perseus.org/api/cts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicesapi.text import CtsAPI\n",
    "cts = CtsAPI(dices_api=api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib for figures\n",
    "\n",
    "Let's also import **pyplot**, for drawing a simple bar graph of the results. Note the Jupyter magic `%matplotlib inline` to display the figure right in the notebook. Some people like `%matplotlib notebook` better â€” it gives you some fancier display options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the speeches\n",
    "\n",
    "### First, the speech metadata from DICES\n",
    "\n",
    "Using the API, we can search speeches using a set of key-value pairs. For now, JSON results from the API are paged, so if your search has a lot of results, you may have to wait for several pages to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = api.getSpeeches(spkr_name='Achilles', work_title='Iliad', progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, the text of the speeches from Perseus\n",
    "\n",
    "This involves retrieving each passage from the CTS server, and extracting the plaintext of its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = NotebookPBar(max=len(speeches))\n",
    "\n",
    "# iterate over all speeches\n",
    "for s in speeches:\n",
    "    \n",
    "    # retrieve the passage from the remote library\n",
    "    s.passage = cts.getPassage(s)\n",
    "    \n",
    "    if s.passage is None:\n",
    "        print(f'Failed to download {speech.urn}')\n",
    "        \n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CLTK's NLP pipeline\n",
    "\n",
    "We run a stripped-down version of CLTK's default NLP pipeline, specific to the speech's language. By default, our wrapper method around the NLP pipeline also creates an index recording the locus of each token. For this example, I'm going to turn that feature off to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = NotebookPBar(max=len(speeches))\n",
    "\n",
    "# iterate over all speeches\n",
    "for s in speeches:\n",
    "    \n",
    "    # parse with CLTK\n",
    "    s.passage.runCltkPipeline(index=False)\n",
    "    \n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count words in each speech\n",
    "\n",
    "`Passage.cltk_doc` gives us acces to the `Doc` object created by CLTK's `NLP()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for s in speeches:\n",
    "    for addressee in s.addr:\n",
    "        count[addressee.name] = count.get(addressee.name, 0) + len(s.passage.cltk_doc.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results\n",
    "\n",
    "ðŸ¤” Let's see whether it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in sorted(count):\n",
    "    print(name, count[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a simple graph with pyplot\n",
    "\n",
    "Seems good. Let's visualize it with a simple bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for the graph\n",
    "names = sorted(count)\n",
    "y_pos = range(len(names))\n",
    "bars = [count[name] for name in names]\n",
    "\n",
    "# create a new figure\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# draw the bars\n",
    "ax.barh(y_pos, bars, align='center')\n",
    "\n",
    "# annotate the graph\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(names)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Number of Words')\n",
    "ax.set_ylabel('Addressee')\n",
    "ax.set_title('Length of Achilles\\' speeches')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP with SpaCy\n",
    "\n",
    "The DICES text module also provides wrappers around SpaCy's NLP pipeline. This produces a different parsing of the text with different relative strengths. Running SpaCy via the DICES library is parallel to running CLTK, and the resulting output is very similar in structure; attributes of the tokens have slightly different names and properties, though. \n",
    "\n",
    "By default, the SpaCy wrapper uses Jacobo Myerston's [grc_proiel_sm](https://huggingface.co/Jacobo/grc_proiel_sm) for Greek and LatinCy's [la_web_core_sm](https://huggingface.co/latincy/la_core_web_sm) for Latin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = NotebookPBar(max=len(speeches))\n",
    "\n",
    "# iterate over all speeches\n",
    "for s in speeches:\n",
    "    \n",
    "    # parse with SpaCy\n",
    "    s.passage.runSpacyPipeline(index=False)\n",
    "    \n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count words using SpaCy\n",
    "\n",
    "`Passage.spacy_doc` gives us acces to a Spacy Doc object that, like the CLTK doc, can be treated as a container of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for s in speeches:\n",
    "    for addressee in s.addr:\n",
    "        count[addressee.name] = count.get(addressee.name, 0) + len(s.passage.spacy_doc)\n",
    "        \n",
    "for name in sorted(count):\n",
    "    print(name, count[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for the graph\n",
    "names = sorted(count)\n",
    "y_pos = range(len(names))\n",
    "bars = [count[name] for name in names]\n",
    "\n",
    "# create a new figure\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# draw the bars\n",
    "ax.barh(y_pos, bars, align='center')\n",
    "\n",
    "# annotate the graph\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(names)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Number of Words')\n",
    "ax.set_ylabel('Addressee')\n",
    "ax.set_title('Length of Achilles\\' speeches')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
