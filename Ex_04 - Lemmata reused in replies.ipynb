{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicesapi import DicesAPI\n",
    "api = DicesAPI(dices_api='http://localhost:8000/api')\n",
    "# this is just to provide progress bars in Jupyter\n",
    "from dicesapi.jupyter import NotebookPBar\n",
    "api._ProgressClass = NotebookPBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing corpora:\n",
      " - latin_models_cltk\n",
      " - latin_text_perseus\n",
      " - latin_treebank_perseus\n",
      " - latin_lexica_perseus\n",
      " - greek_models_cltk\n",
      " - greek_text_perseus\n",
      " - greek_treebank_perseus\n",
      " - greek_lexica_perseus\n"
     ]
    }
   ],
   "source": [
    "from cltk.corpus.utils.importer import CorpusImporter\n",
    "corpora = [\n",
    "    '{}_models_cltk',\n",
    "    '{}_text_perseus',\n",
    "    '{}_treebank_perseus',\n",
    "    '{}_lexica_perseus',\n",
    "]\n",
    "\n",
    "print('Importing corpora:')\n",
    "\n",
    "for lang in ['latin', 'greek']:\n",
    "    downloader = CorpusImporter(lang)\n",
    "    for corpus in corpora:\n",
    "        print(\" - \" + corpus.format(lang))\n",
    "        downloader.import_corpus(corpus.format(lang))\n",
    "\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "tokenizer = {\n",
    "    'greek': WordTokenizer('greek'),\n",
    "    'latin': WordTokenizer('latin'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download some speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = api.getSpeeches(work_title='Iliad', progress=True) + \\\n",
    "            api.getSpeeches(work_title='Odyssey', progress=True)\n",
    "speeches.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the text of the speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = [None] * len(speeches)\n",
    "\n",
    "# create a progress bar\n",
    "pbar = widgets.IntProgress(\n",
    "    value = 0,\n",
    "    min = 0,\n",
    "    max = len(speeches),\n",
    "    bar_style='info',\n",
    "    orientation='horizontal'\n",
    ")\n",
    "pbar_label = widgets.Label(value = f'Downloading {pbar.value}/{len(speeches)}')\n",
    "display(widgets.HBox([pbar, pbar_label]))\n",
    "\n",
    "# download text of speeches\n",
    "for i, s in enumerate(speeches):\n",
    "    cts_passage = s.getCTS()\n",
    "    text = cts_passage.text\n",
    "    passages[i] = text\n",
    "    pbar.value = i\n",
    "    pbar_label.value = f'Downloading {i+1}/{len(speeches)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.lemmatize.latin.backoff import BackoffLatinLemmatizer\n",
    "from cltk.lemmatize.greek.backoff import BackoffGreekLemmatizer\n",
    "lemmatizer = {\n",
    "    'greek': BackoffGreekLemmatizer(),\n",
    "    'latin': BackoffLatinLemmatizer(),    \n",
    "}\n",
    "\n",
    "# regular expressions to tidy up perseus texts for ctlk\n",
    "replacements = {\n",
    "    'greek': [\n",
    "        (r'Â·', ','),           # FIXME: raised dot? \n",
    "        (chr(700), chr(8217)), # two different apostrophes that look alike\n",
    "    ],\n",
    "    'latin': [\n",
    "        \n",
    "    ],\n",
    "}\n",
    "\n",
    "# compile the regexes\n",
    "for lang in ['greek', 'latin']:\n",
    "    replacements[lang] = [(re.compile(pat), repl) for pat, repl in replacements[lang]]\n",
    "    \n",
    "\n",
    "# generic tokenize-lemmatize function\n",
    "def lemmatize(text, lang):\n",
    "    '''return a set of (token,lemmata) pairs for a string'''\n",
    "    \n",
    "    for pat, repl in replacements[lang]:\n",
    "        text = pat.sub(repl, text)\n",
    "    \n",
    "    tokens = tokenizer[lang].tokenize(text)\n",
    "    lemmata = lemmatizer[lang].lemmatize(tokens)\n",
    "    \n",
    "    return lemmata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmata = [None] * len(passages)\n",
    "\n",
    "# create a progress bar\n",
    "pbar = widgets.IntProgress(\n",
    "    value = 0,\n",
    "    min = 0,\n",
    "    max = len(speeches),\n",
    "    bar_style='info',\n",
    "    orientation='horizontal'\n",
    ")\n",
    "pbar_label = widgets.Label(value = f'Lemmatizing {pbar.value}/{len(passages)}')\n",
    "display(widgets.HBox([pbar, pbar_label]))\n",
    "\n",
    "# download text of speeches\n",
    "for i, p in enumerate(passages):\n",
    "    lang = speeches[i].work.lang\n",
    "    lemmatized = lemmatize(p.lower(), lang)\n",
    "    lemmata[i] = lemmatized\n",
    "    pbar.value = i\n",
    "    pbar_label.value = f'Lemmatizing {i+1}/{len(passages)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two speeches to see whether they share lemmata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_comp(lemmatized_a, lemmatized_b, inc_punc=False):\n",
    "    lems_a = set([lem for tok, lem in lemmatized_a])\n",
    "    lems_b = set([lem for tok, lem in lemmatized_b])\n",
    "    shared = set([lem for lem in lems_a if lem in lems_b])\n",
    "    \n",
    "    if not inc_punc:\n",
    "        if 'punc' in shared:\n",
    "            shared = set([lem for lem in shared if lem != 'punc'])\n",
    "    \n",
    "    return shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(lemmata)):\n",
    "    if speeches[i].part > 1:\n",
    "        shared = lem_comp(lemmata[i-1], lemmata[i])\n",
    "        \n",
    "        print('\\t'.join([\n",
    "            str(speeches[i-1]),\n",
    "            str(speeches[i]),\n",
    "            str(len(passages[i-1])),\n",
    "            str(len(passages[i])),\n",
    "            str(len(shared)),\n",
    "            str(shared)\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_lems_no_reply = []\n",
    "nshared_no_reply = []\n",
    "\n",
    "for i in range(len(speeches)):\n",
    "    if speeches[i].part > 1:\n",
    "        j = random.randint(0, len(speeches)-1)\n",
    "        shared = lem_comp(lemmata[i], lemmata[j])\n",
    "        print('\\t'.join([\n",
    "            str(speeches[i-1]),\n",
    "            str(speeches[i]),\n",
    "            str(len(passages[i-1])),\n",
    "            str(len(passages[i])),\n",
    "            str(len(shared)),\n",
    "            str(shared)\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.boxplot([nshared_reply, nshared_no_reply])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
